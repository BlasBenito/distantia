---
title: "Handling Time Series Lists"
output: 
  rmarkdown::html_document:
    toc: true
    toc_title: "Content"
    source: false
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  eval = TRUE,
  collapse = TRUE,
  comment = "#>",
  dpi = 150,
  fig.show = 'hold',
  fig.width = 5
)

options(scipen = 9999)
```


## Summary

The R package `distantia` 2.0 introduces Time Series Lists as working unit for dissimilarity analyses, and provides a complete toolset to manages them.

This article describes Time Series Lists in detail, and showcases the most common data handling procedures enabled by the new functions included in the package. 

## Introduction to Time Series Lists

In this new version of `distantia`, groups of time series are organized as named lists of [zoo](https://cran.r-project.org/web/packages/zoo/index.html) objects. These lists are named **Time Series Lists** (TSL) within the package, and are designed to facilitate the parallelization of dissimilarity analyses. 

TSL is not a class by choice, as the idea is keeping them as simple as possible to grant users the autonomy to create or modify them as needed.

### Zoo Time Series

The R package `zoo` provides an S3 class of the same name designed to handle observations ordered by an index. It supports various index classes, such as Date, POSIXct, or even custom numeric or character indices, and handles regular and irregular time series equally well.

Other advantages of using zoo objects include a seamless intergration with base R methods, and built-in tools for alignment, merging, and subsetting.

Let's take a look at a little zoo object.

```{r, fig.height=2.5}
library(distantia)

z <- distantia::zoo_simulate(
  name = "my_zoo",
  cols = 3,
  rows = 10,
  time_range = c(
    "2024-01-01", 
    "2024-12-31"
    ),
  na_fraction = 0.1,
  irregular = TRUE,
  seed = 1
)

zoo_plot(x = z)
```

Zoo objects have two main components, a data matrix with the time series observations, and an index representing time or sample order.

The data matrix is extracted with `zoo::coredata()`.

```{r}
zoo::coredata(z)
class(zoo::coredata(z))
```
The core data of a zoo object can also be a vector when the time series is univariate.

```{r}
x <- zoo::zoo(x = runif(10))
is.vector(zoo::coredata(x))
```
However, this is **frowned upon** in `distantia`, and these vectors should always be converted to matrices.

```{r}
x <- distantia::zoo_vector_to_matrix(x = x)
is.vector(zoo::coredata(x))
is.matrix(zoo::coredata(x))
```

The index of zoo time series is extracted with `zoo::index()`.

```{r}
zoo::index(z)
class(zoo::index(z))
```
The classes for zoo indices explicitly supported in `distantia` are `Date`, `POSIXct`, and `numeric`. The function `distantia::zoo_time()` helps summarize the time features of a zoo object

```{r}
distantia::zoo_time(x = z)
```

Additionally, in `distantia` all zoo objects are expected to have the attribute `name`.

```{r}
attributes(z)$name
```
This attribute is used to facilitate plotting operations, and it is managed internally by `tsl_...()` functions. There are several functions in `distantia` to manage the names of zoo objects.

```{r}
#reset zoo name
z <- distantia::zoo_name_set(
  x = z,
  name = "My_Zoo"
)

#get zoo name
distantia::zoo_name_get(x = z)

#clean zoo name
z <- distantia::zoo_name_clean(
  x = z,
  lowercase = TRUE
)

distantia::zoo_name_get(x = z)
```
This package comes with several functions to manipulate zoo objects:

  - `zoo_name_set()`, `zoo_name_get()` and `zoo_name_clean()`: handle the attribute "name".
  - `zoo_time()`: details of the zoo index.
  - `zoo_aggregate()`: time aggregation of zoo objects.
  - `zoo_resample()`: interpolation or extrapolation to a different time, or from irregular to regular time.
  - `zoo_permute()`: restricted permutation.
  - `zoo_vector_to_matrix()` and `zoo_to_tsl()`: internal functions to facilitate handling zoo objects within TSLs.

### Time Series Lists (TSL)

TSLs are *named* lists of zoo time series. The example below shows how to build a TSL from scratch with zoo objects. But this is not the most common or comfortable case, so please, visit the section **Creating Time Series Lists** to find out how to convert your data easily to TSL.

```{r}
#create simple tsl
my_tsl <- list(
  A = distantia::zoo_simulate(
    cols = 4,
    na_fraction = 0.2
  ),
  B = distantia::zoo_simulate()
)

names(my_tsl)

class(my_tsl)

#names of the zoo objects
lapply(X = my_tsl, FUN = distantia::zoo_name_get)

#class of the objects within the list
lapply(X = my_tsl, FUN = class)
```

TSLs ready for dissimilarity analyses **must follow several rules**:

  - The elements of the list or the zoo objects must be named.
  - Time series names cannot be duplicated.
  - The coredata of all zoo objects must be of class `matrix`.
  - There cannot be NA, Inf, or NaN in the zoo objects.
  - All zoo columns must be named.
  - All zoo columns must be numeric.
  - All zoo objects within the TSL must share at least one column name.
  - The index of the zoo objects must be of the same class.
  
These are many rules, I know, but the functions `tsl_diagnose()` and `tsl_repair()` are there to help you forget about them.

When applying `tsl_diagnose()` to `my_tsl` we can see it has several issues.

```{r}
distantia::tsl_diagnose(tsl = my_tsl)
```
From there, we can either follow the suggestions, or apply `tsl_repair()` directly, as done below.

```{r}
my_tsl <- distantia::tsl_repair(tsl = my_tsl)
```
This function identifies the issues raised up by `tsl_diagnose()` and repairs them when possible.

If we run `tsl_diagnose()` again, all checks should be ok.

```{r}
distantia::tsl_diagnose(
  tsl = my_tsl
)
```

From this point, our TSL is ready to go!

```{r, fig.height=2.5}
distantia::tsl_plot(
  tsl = my_tsl,
  guide = FALSE
)
```

## Creating TSLs

The function `tsl_initialize()` (with the alias `tsl_init()`) is designed to help transform several data structures to Time Series List.

### Long Data Frame to TSL

Long and tidy data frames are convenient structures to store multivariate time series of a reasonable size. For example, the data frame `fagus_dynamics` shown below has the column "name" identifying separate time series, the column "time" with observation dates, and three numeric columns with environmental observations.

```{r}
head(fagus_dynamics)
```
Transforming this data frame to TSL is quite straightforward:

```{r, fig.height=4}
tsl <- distantia::tsl_initialize(
  x = fagus_dynamics,
  name_column = "name",
  time_column = "time"
)

#even shorter!
tsl <- distantia::tsl_init(
  x = fagus_dynamics,
  name = "name",
  time = "time"
)

distantia::tsl_plot(
  tsl  = tsl
)
```
Once manipulated and/or analyzed, a TSL can be converted back to data frame with `tsl_to_df()`.

```{r}
df <- distantia::tsl_to_df(tsl = tsl)
head(df)
```

### Wide Data Frame to TSL

```{r, echo = FALSE}
evi_wide <- stats::reshape(
  data = fagus_dynamics[, c(
    "name",
    "time",
    "evi"
  )],
  timevar = "name",
  idvar = "time",
  direction = "wide",
  sep = "_"
)
```

A wide data frame is a useful structure to store univariate time series observed in different places at the same times.

```{r}
head(evi_wide)
```
When no `name_column` is provided, `tsl_initialize()` assumes that the time series are coded as separate columns.

```{r, fig.height=3}
tsl <- distantia::tsl_initialize(
  x = evi_wide,
  time_column = "time"
  )

tsl_plot(
  tsl = tsl,
  guide = FALSE
)
```
In this case, the column names of the univariate zoo objects will have the same name ("x").

```{r}
distantia::tsl_colnames_get(tsl = tsl)
```
This name can be reset as needed with `tsl_colnames_set()`.

```{r}
tsl <- distantia::tsl_colnames_set(
  tsl = tsl,
  names = "evi"
)

distantia::tsl_colnames_get(tsl = tsl)
```
This TSL can be converted to data frame, but this time the result comes in long format.

```{r}
df <- distantia::tsl_to_df(tsl = tsl)
head(df)
```

### Vectors and Matrices to TSL

A list of numeric vectors can also be converted to TSL. In this case, the zoo index is a sequence of integers.

```{r, fig.height=2.5}
tsl <- distantia::tsl_initialize(
  x = list(
    a = runif(10),
    b = runif(10)
  )
)

distantia::tsl_plot(
  tsl = tsl,
  guide = FALSE
)
```

The same thing can be done with matrices as well.

```{r, fig.height=2.5}
tsl <- distantia::tsl_initialize(
  x = list(
    a = matrix(data = runif(100), ncol = 2, nrow = 50),
    b = matrix(data = runif(100), ncol = 2, nrow = 50)
  )
)

distantia::tsl_plot(
  tsl = tsl,
  guide = FALSE
)
```

## The TSL Toolset

All functions in `distantia` to handle TSLs are named `tsl_...()`. Several of these functions are designed to explore and better understand your TSLs, while others are designed to manipulate and transform them to facilitate dissimilarity analyses.

### Parallelization Setup

All TSL functions have something in common: **they are a bunch of `lapply` in a trench coat**. Most use a parallelized version of `lapply` from the `future.apply` package, `future.apply::future_lapply()`, and a few combine `foreach::foreach()` with `doFuture::`%dofuture%` in parallelized loops.

As such, they all support a parallelization backend provided by the `future` package, as shown below.

```{r}
library(future)
library(parallelly)

future::plan(
  future::multisession,
  workers = parallelly::availableCores() - 1
  )

#progress bar (does not work in Rmarkdown)
#progressr::handlers(global = TRUE)
```

They also support progress bars via the [`progressr`](https://progressr.futureverse.org/) package. However, this option, commented in the code above, does not work in Rmarkdown.

### Explore TSLs

This section showcases the tools available in `distantia` to extract details from our Time Series Lists. But first, let's create a simulated TSL.

```{r, fig.height=4}
tsl <- distantia::tsl_simulate(
  n = 4,
  rows = 1000,
  seasons = 10,
  na_fraction = 0.1,
  irregular = TRUE
)

tsl_plot(
  tsl = tsl,
  guide = FALSE
  )
```

The most general tools in this section are focused on simple things such as TSL names and dimensions.

```{r}
#time series names
distantia::tsl_names_get(tsl = tsl)

#time series column names
distantia::tsl_colnames_get(tsl = tsl)

#number of columns
distantia::tsl_ncol(tsl = tsl)

#number of roes
distantia::tsl_nrow(tsl = tsl)
```

The function `tsl_time()` analyzes the time features of all time series in a TSL and generates a data frame.

```{r}
distantia::tsl_time(tsl = tsl)
```

The function `tsl_stats()` focuses on the data values instead to provides a summary of their stats by time series and variable.

```{r}
df_stats <- distantia::tsl_stats(
  tsl = tsl, 
  lags = 1 #temporal autocorrelation lag
  )

df_stats
```
### Handle NA Cases

Dissimilarity analyses with `distantia`, because they designed with computational efficiency in mind, **do not support NA cases**. 

There are two alternate workflows to handle NA data in time series list.

The first uses `tsl_count_NA()` and `tsl_handle_NA()`. The former converts Inf and NaN to NA and counts NA cases in each time series, while the latter either omits or imputes NA cases via `zoo::na.approx()`.

```{r}
#count NA
distantia::tsl_count_NA(tsl = tsl) 

#impute NA cases
tsl_notNA <- distantia::tsl_handle_NA(
  tsl = tsl,
  na_action = "impute"
)

#re-count
distantia::tsl_count_NA(tsl = tsl_notNA) 
```
The second workflow is more general because it can address other potential issues. It involves using `tsl_diagnose()` and `tsl_repair()`.

```{r}
#diagnose issues with NA values
distantia::tsl_diagnose(tsl = tsl)

#impute NA cases
tsl <- tsl_repair(tsl = tsl)

#re-diagnose to check result
distantia::tsl_diagnose(tsl = tsl)
```

### Subsetting

The function `tsl_subset()` helps focus on particular *regions* of a time series list. Additionally, this function returns by default the numeric columns that are shared across all time series in a TSL.

```{r, fig.height=3.5}
distantia::tsl_names_get(tsl = tsl)
distantia::tsl_colnames_get(tsl = tsl)
distantia::tsl_time(tsl = tsl)[, c("name", "begin", "end")]

tsl_new <- distantia::tsl_subset(
  tsl = tsl,
  names = c("A", "C", "D"),
  colnames = c("a", "b"),
  time = c("2014-01-01", "2018-01-01")
)


distantia::tsl_names_get(tsl = tsl_new)
distantia::tsl_colnames_get(tsl = tsl_new)
distantia::tsl_time(tsl = tsl_new)[, c("name", "begin", "end")]

distantia::tsl_plot(
  tsl = tsl_new,
  guide = FALSE
  )
```

The function `tsl_burst()` transforms a multivariate TSL into a univariate TSL by creating a new zoo object from each column of the original zoo objects. This function helps apply dissimilarity analysis between individual variables in multivariate time series.


```{r, fig.height=6}
#burst multivariate time series to univariate
tsl_univariate <- distantia::tsl_burst(
  tsl = tsl_new
)

#check new names and column names
distantia::tsl_names_get(tsl = tsl_univariate)
distantia::tsl_colnames_get(tsl = tsl_univariate)

#plot univariate time series
distantia::tsl_plot(
  tsl = tsl_univariate,
  guide = FALSE
  )
```

### Aggregation

Aggregation summarizes multiple data points into a single value over a specified time interval. It reduces the number of samples, smooths noise out, can transform irregular time series into regular, and generate entirely new time series depending on the aggregation stats. On the other hand, it obscures fine grain detail and alters statistical properties such as variance and autocorrelation.

In `distantia`, this operation is supported by the function `tsl_aggregate()`. This function has two arguments:

 - `new_time`: time vector or keyword defining time intervals to aggregate over.
 - `f`: aggregation function summarizing observations over aggregation time intervals.
 
The code below illustrates the usage of `tsl_aggregate()` to compute yearly temperature and precipitation indicators from the monthly observations of the dataset `honeycomb_climate`.

```{r, fig.height=5}
tsl <- distantia::tsl_init(
  x = distantia::honeycomb_climate,
  name = "cell",
  time = "time"
) |> 
  tsl_subset(
    names = 1:5 #subset first five elements
  )

distantia::tsl_plot(
  tsl = tsl
)
```

The easiest way to define aggregation intervals in `distantia` is to use a keyword. The function `tsl_time()` returns the supported keywords for a given TSL.

```{r}
df <- distantia::tsl_time(
  tsl = tsl,
  keywords = "aggregate"
  )

df$keywords |> 
  unlist() |> 
  unique()
```
Let's settle for "quarters" in this example.

```{r}
interval <- "quarters"
```

The code below subsets the column "temperature" in `tsl`, computes the yearly minimum, maximum, and mean, adds a suffix to each stats, and join all results in a new time series list.

```{r, fig.height=5}
#subset temperature column
tsl_temperature <- distantia::tsl_subset(
  tsl = tsl,
  colnames = "temperature"
)

#compute stats: minimum, maximum, and mean
tsl_temperature_min <- distantia::tsl_aggregate(
  tsl = tsl_temperature,
  new_time = interval,
  f = min
) |> 
  distantia::tsl_colnames_suffix(
    suffix = "_min" #set suffix for aggregated column
  )

tsl_temperature_max <- distantia::tsl_aggregate(
  tsl = tsl_temperature,
  new_time = interval,
  f = max
) |> 
  distantia::tsl_colnames_suffix(
    suffix = "_max"
  )

tsl_temperature_mean <- distantia::tsl_aggregate(
  tsl = tsl_temperature,
  new_time = interval,
  f = mean
) |> 
  distantia::tsl_colnames_suffix(
    suffix = "_mean"
  )

#join stats together
tsl_temperature_stats <- distantia::tsl_join(
  tsl_temperature_min,
  tsl_temperature_max,
  tsl_temperature_mean
)

#plot first 
tsl_plot(
  tsl = tsl_temperature_stats
)
```
Something similar can be done with the precipitation column.

```{r, fig.height=5}
#subset temperature column
tsl_precipitation <- distantia::tsl_subset(
  tsl = tsl,
  colnames = "precipitation"
)

#compute stats: minimum, maximum, and mean
tsl_precipitation_sum <- distantia::tsl_aggregate(
  tsl = tsl_precipitation,
  new_time = interval,
  f = sum
) |> 
  distantia::tsl_colnames_suffix(
    suffix = "_sum" #set suffix for aggregated column
  )

tsl_precipitation_max <- distantia::tsl_aggregate(
  tsl = tsl_precipitation,
  new_time = interval,
  f = max
) |> 
  distantia::tsl_colnames_suffix(
    suffix = "_max"
  )

tsl_precipitation_min <- distantia::tsl_aggregate(
  tsl = tsl_precipitation,
  new_time = interval,
  f = min
) |> 
  distantia::tsl_colnames_suffix(
    suffix = "_min"
  )

#join stats together
tsl_precipitation_stats <- distantia::tsl_join(
  tsl_precipitation_sum,
  tsl_precipitation_max,
  tsl_precipitation_min
)

#plot first 
tsl_plot(
  tsl = tsl_precipitation_stats
)
```
To finalize this section, we join together the resuls of all aggregations.

```{r, fig.height=5}
tsl_climate_stats <- tsl_join(
  tsl_temperature_stats,
  tsl_precipitation_stats
)

tsl_plot(
  tsl = tsl_climate_stats
)
```

### Resampling

### Smoothing

### Data Transformations

The function `tsl_transform()` applies a function `f` to transform the values of a TSL. The names of the available `f` functions can be listed with `f_list()`.

```{r}
distantia::f_list()
```

Let's take a look at a few examples.

#### Scaling

Scaling and centering multivariate time series is essential in dynamic time warping to ensure all variables contribute equally, regardless of their range or units.

For example, the dataset `fagus_dynamics` has variables in different units.

```{r, fig.height=3.5, message=FALSE}
tsl <- distantia::tsl_init(
  x = distantia::fagus_dynamics,
  name = "name",
  time = "time"
)

distantia::tsl_plot(
  tsl = tsl
)
```
Due to the differences in magnitude between variables, a dynamic time warping analysis will focus on `rainfall` disproportionately, biasing the results. 

To solve this issue, the package `distantia` implements two flavors of scaling and/or centering:

  - **Local**: each variable is scaled and/or centered independently by time series.
  - **Global**: each variable is scaled and/or centering using its mean and standard deviation across all time series.

```{r, fig.height=3.5, message=FALSE}
#local scaling
tsl_local_scaling <- distantia::tsl_transform(
  tsl = tsl,
  f = distantia::f_scale_local,
  scale = TRUE, #default
  center = TRUE #default
)

#global scaling
tsl_global_scaling <- distantia::tsl_transform(
  tsl = tsl,
  f = distantia::f_scale_global,
  scale = TRUE, #default
  center = TRUE #default
)
```


The stats of both scalings show that the global one preserves variable offsets between locations, while in the local one all variables have a mean ~0.

```{r}
stats_cols <- c("name", "variable", "mean", "sd")

#stats of local scaling
distantia::tsl_stats(
  tsl = tsl_local_scaling
)[, stats_cols]

#stats of global scaling
distantia::tsl_stats(
  tsl = tsl_global_scaling
)[, stats_cols]
```

The functions `f_rescale_local` and `f_rescale_global` work under the same principle to rescale variable ranges. By default, these functions rescale all time series between 0 and 1, but the arguments `new_min` and `new_max` can receive numeric vectors to set different ranges per variable.

```{r}
tsl_rescaled_local <- tsl_transform(
  tsl = tsl,
  f = f_rescale_local,
  new_min = 0, #same for all variables
  new_max = c(0, 100, 10)
)

tsl_rescaled_global <- tsl_transform(
  tsl = tsl,
  f = f_rescale_global,
  new_min = 0,
  new_max = c(0, 100, 10)
)
```

The stats below show the results of the local and global rescaling.

```{r}
stats_cols <- c("name", "variable", "min", "max")

distantia::tsl_stats(
  tsl = tsl_rescaled_local
)[, stats_cols]

distantia::tsl_stats(
  tsl = tsl_rescaled_global
)[, stats_cols]
```

#### Detrending

Removing trends in time series before applying dynamic time warping is crucial because it prevents inflated distance measurements caused by non-stationary components and ensures that the alignment focuses on meaningful shape features rather than being distorted by long-term trends.

The transformation function `f_trend_linear` transforms time series into their linear trend. The example below applies this function to the `cities_temperature` dataset.

```{r, fig.height=10}
#loading cities_temperature as tsl
tsl <- distantia::tsl_init(
  x = distantia::cities_temperature,
  name = "name",
  time = "time"
)

#computing linear trends
tsl_trend <- distantia::tsl_transform(
  tsl = tsl,
  f = distantia::f_trend_linear
)

#plotting linear trends
tsl_plot(
  tsl = tsl_trend,
  columns = 2,
  guide = FALSE,
  color = "red4",
  width = 1.5
)
```

We can now compute the stats of these linear trends to identify the cities with a steeper long-term temperature change.

```{r}
#compute stats of linear trends
df_stats <- distantia::tsl_stats(
  tsl = tsl_trend,
  lags = 0
)

#arrange from higher to lower range
df_stats[
  order(df_stats$range, decreasing = TRUE), 
  c("name", "range")
  ]
```

The function `f_detrend_linear` removes these temporal trends from the data.

```{r}
tsl_detrended <- distantia::tsl_transform(
  tsl = tsl,
  f = distantia::f_detrend_linear
)
```

With the code below we can check that the linear detrending actually removed linear trends from the data.

```{r, fig.height=10}
tsl_trend <- distantia::tsl_transform(
  tsl = tsl_detrended,
  f = distantia::f_trend_linear
)

df_stats <- distantia::tsl_stats(
  tsl = tsl_trend,
  lags = 0
)

df_stats[, c("name", "range")]
```

#### Rowwise Transformations

This section focuses on transformations involving rowwise operations. These are proportions, percentages, and the Hellinger transformation.





