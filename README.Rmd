---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)

#installing required libraries
list.of.packages <- c("ggplot2", "viridis", "fields", "foreach", "parallel", "doParallel", "qgraph", "tidyr")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages, dep=TRUE)

```
# distantia

<!-- badges: start -->
<!-- badges: end -->

The package **distantia** allows to measure the dissimilarity between multivariate time-series (*sequences* hereafter). The package assumes that the target sequences are ordered along a given dimension, being depth and time the most common ones, but others such as latitude or elevation are also suitable. Furthermore, the target sequences can be regular or irregular, and have their samples aligned (same age/time/depth) or unaligned (different age/time/depth). The only requirement is that the sequences must have at least two (but ideally more) columns with the same name and units.

In this document I briefly explain the logics behind the method, show how to use it, and demonstrate how the **distantia** package introduces useful tools to compare multivariate time-series.

## Installation

You can install the released version of distantia from [CRAN](https://CRAN.R-project.org) with:

```{r, eval=FALSE}
# install.packages("distantia")
```

And the development version from [GitHub](https://github.com/) with:

```{r, eval=FALSE, message=FALSE}
install.packages("devtools")
library(devtools)
devtools::install_github("BlasBenito/distantia")
```

Loading the library, plus other helper libraries:

```{r, message=FALSE, warning=FALSE, error=FALSE, eval=TRUE}
library(distantia)
library(ggplot2)
library(viridis)
library(kableExtra)
library(qgraph)
library(tidyr)
```


## Working with two irregular and unaligned sequences

### Preparing the data

This section assumes that the user wants to compare two sequences. The package provides two example datasets based on the Abernethy pollen core (Birks and Mathewes, 1978):

```{r, eval=TRUE}
data(sequenceA)
data(sequenceB)

str(sequenceA)
str(sequenceB)

kable(sequenceA, caption = "Sequence A")
kable(sequenceB, caption = "Sequence B")
```

Notice that **sequenceB** has a few NA values (that were introduced to serve as an example). The function **prepareSequences** gets them ready for analysis by matching colum names and handling empty data. It allows to merge two (or more) multivariate time-series into a single table ready for further analyses. Note that, since the data represents pollen abundances, a *Hellinger* transformation (square root of the relative proportions of each taxa) is applied.

```{r, eval=TRUE}
help(prepareSequences)

AB.sequences <- prepareSequences(
  sequence.A = sequenceA,
  sequence.A.name = "A",
  sequence.B = sequenceB,
  sequence.B.name = "B",
  merge.mode = "complete",
  if.empty.cases = "zero",
  transformation = "hellinger"
)

kable(AB.sequences)
```



### Computation of dissimilarity

The computation of dissimlarity between two sequences requires several steps.

**1. Computation of a distance matrix** among the samples of both sequences. It is computed by the **distanceMatrix** function, which allows the user to select a distance metric (so far the ones implemented are *manhattan*, *euclidean*, *chi*, and *hellinger*). The function **plotMatrix** allows an easy visualization of the distance matrix.

```{r, fig.width = 7, fig.height = 4, eval=TRUE, fig.cap = "Distance matrix of two irregular and unaligned multivariate sequences. Warmer colors indicate higher distance."}
#computing distance matrix
AB.distance.matrix <- distanceMatrix(
  sequences = AB.sequences,
  method = "manhattan"
)

#plotting distance matrix
plotMatrix(
  distance.matrix = AB.distance.matrix,
  color.palette = "viridis")
```

**2. Computation of the least-cost matrix within the distance matrix.** This step uses a *dynamic programming algorithm* to find the least-cost when moving between the cell 1,1 of the matrix (lower left in the image above) and the last cell of the matrix (opposite corner). It does so by solving first every partial solution (in the neighborhood of every cell in the matrix), and then propagating the sum towards the opposite extreme of the matrix. 

The value of the upper-right cell in the plotted matrix (actually, the lower-right cell in the actual data matrix, the matrix is rotated in the plot) is the sum of the minimum distance across all samples of both time-series.

```{r, fig.width = 7, fig.height = 4, eval=TRUE, fig.cap = "Least cumulative cost of moving between the lower-left cell and the upper-right cell. The value of the upper-right cell corresponds with the minimized sum of distances between the samples of both sequences."}
AB.least.cost.matrix <- leastCostMatrix(
  distance.matrix = AB.distance.matrix
)

plotMatrix(
  distance.matrix = AB.least.cost.matrix,
  color.palette = "viridis")
```

**Optional** In this optional step, the function **leastCostPath** finds the least-cost path in the matrix above. It returns a dataframe with the coordinates of the cells within the path, the distance between consecutive cells, and the cumulative distance of any given step in the path. It can be used to plot the path, which helps to better understand the alignmnet between both sequences. 

This dataframe will be used later on to generate other products, such the *slotting* of both sequences (a unique sequences with the samples of both sequences in the order that minimizes the distance between consecutive samples), or to transfer attributes such as age/time/depth from one sequence with them to another without them. **Note: these applications are not yet implemented**.
 
```{r, fig.width = 7, fig.height = 4, eval=TRUE, fig.cap = "least-cost path plotted on top of the distance matrix."}
AB.least.cost.path <- leastCostPath(
  distance.matrix = AB.distance.matrix,
  least.cost.matrix = AB.least.cost.matrix
  )

kable(AB.least.cost.path)

par(mfrow=c(2,1))
plotMatrix(
  distance.matrix = AB.distance.matrix,
  least.cost.path = AB.least.cost.path,
  color.palette = viridis(100, alpha = 0.7)
  )
```

```{r, fig.width = 7, fig.height = 4, eval=TRUE, fig.cap = "Least-cost path plotted on top of the least-cost matrix."}
plotMatrix(
  distance.matrix = AB.least.cost.matrix,
  least.cost.path = AB.least.cost.path,
  color.palette = viridis(100, alpha = 0.7)
  )
```

**Optional: least cost path using diagonals**.

The least cost path can be computed also in diagonal, which allows to pair together these samples with the higher similarity that contribute to minimize the overall cost of the least cost path.

```{r, fig.width = 7, fig.height = 4, eval=TRUE, fig.cap = "Least cumulative cost of moving between the lower-left cell and the upper-right cell. The value of the upper-right cell corresponds with the minimized sum of distances between the samples of both sequences."}
#computing the least cost using diagonals
diagonal.least.cost <- leastCostMatrix(
  distance.matrix = AB.distance.matrix,
  diagonal = TRUE
)

#computing least cost path using diagonals
diagonal.least.cost.path <- leastCostPath(
  distance.matrix = AB.distance.matrix,
  least.cost.matrix = AB.least.cost.matrix,
  diagonal = TRUE
  )

plotMatrix(
  distance.matrix = diagonal.least.cost,
  least.cost.path = diagonal.least.cost.path,
  color.palette = viridis(100, alpha = 0.7)
  )
```

Using diagonals is useful when the goal is to transfer attributes (time, age, depth, etc) from one sequence with them to another sequence without them. This will be shown later **NOTE: not implemented yet**.


**3. Getting the least-cost value.** The Upper right cell of the least-cost matrix in the image of the least-cost matrix (lower right cell in the actual data-matrix) holds the cumulative sum of the least-cost path. This value will be used later to compute dissimilarity.

```{r, eval=TRUE}
AB.least.cost <- leastCost(
  least.cost.matrix = AB.least.cost.matrix
  )
AB.least.cost
```


**4. Autosum, or sum of the distances among adjacent samples on each sequence.** This is another requirement to compute a normalized measure of dissimilarity. It just computes the distance between adjacent samples of each sequence and sums them up. Notice that the output is a list with named slots. Lists are the main output device of this package, I'll explain later why.

```{r, eval=TRUE}
AB.autosum <- autoSum(
  sequences = AB.sequences,
  method = "manhattan"
  )
AB.autosum
```

**5. Compute dissimilarity.** The dissimilarity measure used in this package is named **psi**, that was first described in the book ["Numerical methods in Quaternary pollen analysis"](https://onlinelibrary.wiley.com/doi/abs/10.1002/gea.3340010406) (Birks and Gordon, 1985). **Psi** is computed as follows:

$$\psi = \frac{LC - (\sum{A_{i-j}} + \sum{B_{i-j}})}{\sum{A_{i-j}} + \sum{B_{i-j}}} $$

where:


+   $LC$ is the least-cost computed by **leastCostMatrix**.
+   $\sum{A_{i-j}}$ is the autosum of one of the sequences.
+   $\sum{B_{i-j}}$ is the autosum of the other sequence.

Which basically is the least-cost normalizado by the autosum of both sequences. The **psi** function only requires the least cost, and the autosum of both sequences, as follows. Notice that in the output list, the slot with the psi value is named after the two sequences separated by a vertical line ("A|B"). This convention will be followed by any function in the package that returns objects resulting from comparing two sequences.

```{r, eval=TRUE}
AB.psi <- psi(
  least.cost = AB.least.cost,
  autosum = AB.autosum
  )
AB.psi
```

The output of **psi** is a list, that can be transformed to a dataframe or a matrix by using the **formatPsi** function.

```{r}
#to dataframe
AB.psi.dataframe <- formatPsi(
  psi.values = AB.psi,
  to = "dataframe")
kable(AB.psi.dataframe)
```

```{r}
#to matrix
AB.psi.matrix <- formatPsi(
  psi.values = AB.psi,
  to = "matrix")
kable(AB.psi.matrix)
```

Or can also be transformed from matrix to dataframe, or from dataframe to matrix, as convenient.

```{r}
#from matrix to dataframe again
AB.psi.dataframe <- formatPsi(
  psi.values = AB.psi.matrix,
  to = "dataframe")
kable(AB.psi.dataframe)
```

```{r}
#or from dataframe to matrix
AB.psi.matrix <- formatPsi(
  psi.values = AB.psi.dataframe,
  to = "matrix"
)
kable(AB.psi.matrix)
```


All the steps required to compute **psi**, including the format options provided by **formatPsi** are wrapped together in the function **workflowPsi**, that works as follows:

```{r, eval=TRUE}
AB.psi <- workflowPsi(
  sequences = AB.sequences,
  grouping.column = "id",
  method = "manhattan",
  format = "dataframe"
)
AB.psi
```

```{r}
#cleaning environment for next example
rm(AB.autosum, AB.distance.matrix, AB.least.cost, AB.least.cost.matrix, AB.least.cost.path, AB.psi, AB.psi.dataframe, AB.psi.matrix, AB.sequences, sequenceA, sequenceB, diagonal.least.cost, diagonal.least.cost.path)
```


# Workflow to compare multiple sequences

The package can work seamlessly with any given number of sequences, as long as there is memory enough available. To do so, almost every function uses the package ["foreach"](https://cran.r-project.org/web/packages/foreach/index.html), that allows to parallelize the execution of the functions by using all the processors in your machine but one. This speeds up operations considerably.

## Preparing the data

The example dataset *sequencesMIS* contains 12 sections of the same sequence belonging to different marine isotopic stages identified by a column named "MIS". MIS stages with odd numbers are interglacials, while the odd ones are glacials. 

```{r, eval=TRUE}
data(sequencesMIS)
kable(head(sequencesMIS, n=15))
unique(sequencesMIS$MIS)
```

The dataset is checked and prepared with **prepareSequences** (note the change in the argument *grouping.column*).

```{r, eval=TRUE}
MIS.sequences <- prepareSequences(
  sequences = sequencesMIS,
  grouping.column = "MIS",
  if.empty.cases = "zero",
  transformation = "hellinger"
)
```

The dissimilarity measure **psi** can be computed for every combination of sequences through the function **workflowPsi** shown below. Note the argument *output* that allows to select either "dataframe" (ordered from lower to higher dissimilarity) or "matrix" to obtain an output with a given structure (if empty, the function returns a list).


```{r, eval=TRUE}
MIS.psi <- workflowPsi(
  sequences = MIS.sequences,
  grouping.column = "MIS",
  time.column = NULL,
  exclude.columns = NULL,
  method = "manhattan",
  diagonal = FALSE,
  format = "dataframe"
)

#ordered with lower psi on top
kable(MIS.psi[order(MIS.psi$psi), ])
```



A dataframe like this can be plotted as an adjacency network with the **qgraph** package as follows:

```{r, fig.width = 7, fig.height = 7, eval=TRUE, fig.cap = "Similarity between MIS sequences represented as a network. More similar sites are closer, and linked by a wider edge. Note that glacials are colored in blue and interglacials in green"}
#psi values to matrix
MIS.psi.matrix <- formatPsi(
  psi.values = MIS.psi,
  to = "matrix"
)

#dissimilariy to distance
MIS.distance <- 1/MIS.psi.matrix**4

#plotting network
qgraph::qgraph(MIS.distance, 
       layout='spring', 
       vsize=5,
       labels = colnames(MIS.distance),
       colors = viridis::viridis(2, begin = 0.3, end = 0.8, alpha = 0.5, direction = -1)
       )

```

Or as a matrix with **ggplot2**.

```{r, fig.width = 7, fig.height = 4, eval=TRUE, fig.cap = "Dissimilarity between MIS sequences. Darker colors indicate a higher dissimilarity."}
#ordering factors to get a triangular matrix
MIS.psi$A <- factor(MIS.psi$A, levels=unique(sequencesMIS$MIS))
MIS.psi$B <- factor(MIS.psi$B, levels=unique(sequencesMIS$MIS))

#plotting matrix
ggplot(data=na.omit(MIS.psi), aes(x=A, y=B, size=psi, color=psi)) + 
  geom_point() +
  viridis::scale_color_viridis(direction = -1) +
  guides(size = FALSE)
```

The dataframe of dissimilarities between pairs of sequences can be also used to analyze the drivers of dissimilarity. To do so, attributes such as differences in time (when sequences represent different times) or distance (when sequences represent different sites) between sequences, or differences between physical/climatic attributes between sequences such as topography or climate can be added to the table, so models such as $psi = A + B + C$ (were A, B, and C are these attributes) can be fitted.

```{r}
#cleaning environment for next example
rm(MIS.distance, MIS.psi, MIS.psi.matrix, MIS.sequences, sequencesMIS)
```


# Working with aligned multivariate time-series 

This section assumes that the target multivariate time-series have the same number of samples/rows, and samples have the same time/depth/order if there is a time/age/depth column available. In this particular case, distances are computed only between samples with the same time/depth/order, and no distance matrix (nor least cost analysis) is required. When the argument *paired.samples* in **prepareSequences** is set to TRUE, the function checks if the sequences have the same number of rows, and, if *time.column* is provided, it selects the samples that have valid time/depth columns for every sequence in the dataset.

Here we test these ideas with the **climate** dataset included in the library. It represents simulated palaeoclimate over 200 ky. at four sites identified by the column *sequenceId*. Note that this time the transformation applied is "scaled", which uses the **scale** function of R base to center and scale the data.

```{r, eval=TRUE}
#loading sample data
data(climate)

#preparing sequences
climate <- prepareSequences(
  sequences = climate,
  grouping.column = "sequenceId",
  time.column = "time",
  paired.samples = TRUE,
  transformation = "scale"
  )
```

The function **distancePairedSamples** computes the between paired samples (same order/time/age/depth), and therefore does not use the least cost algorithm to minimize the distances between sequences shown above. If the argument *time.column* is not provided, or if it's provided but *same.time* is false, the samples are paired by their order (first sample of one sequence vs. the first sample of the other sequence, the second against the second, and so on), and samples that only have an age for one of the sequences are removed from the comparison. This is useful to compare subsets of the same sequence, or subsets of different sequences belonging to different times.

If there is a *time.column* and *same.time* is set to true, only samples with the same time/age/depth are compared. This is useful to compare sequences taken at the same time in different sites.

The result is a list, each slot named as the id of the given sequence according to *grouping.columns*, and containing a vector with pairwise distances. Each vector position is named after *time.column* if available. 

```{r, eval=TRUE}
climate.distances <- distancePairedSamples(
  sequences = climate,
  grouping.column = "sequenceId",
  time.column = "time",
  same.time = TRUE,
  exclude.columns = NULL,
  method = "manhattan",
  sum.distances = FALSE
  )

str(climate.distances)
```

If the argument *sum.distances* is set to TRUE, it sums them up, doing in fact the same work done by **distanceMatrix**, **leastCostMatrix** and **leastCost** at once. 

```{r, eval=TRUE}
climate.distances <- distancePairedSamples(
  sequences = climate,
  grouping.column = "sequenceId",
  time.column = "time",
  exclude.columns = NULL,
  same.time = TRUE,
  method = "manhattan",
  sum.distances = TRUE
  )
climate.distances
```

Computing *psi* from there only requires the autosum of each sequence, and the application of the **psi** function.

```{r, eval=TRUE}
#computing autosum
climate.autosum <- autoSum(
  sequences = climate,
  grouping.column = "sequenceId",
  time.column = "time",
  method = "manhattan"
)

#computing psi
climate.psi <- psi(
  least.cost = climate.distances,
  autosum = climate.autosum
)

climate.psi
```

The function **workflowPsi** executes this sequences when the argument *paired.samples* is set to TRUE, as follows.

```{r, eval=TRUE}
climate.psi <- workflowPsi(
  sequences = climate,
  grouping.column = "sequenceId",
  time.column = "time",
  method = "manhattan",
  paired.samples = TRUE, #this bit is important
  format = "dataframe"
)
kable(climate.psi)
```

```{r}
#cleaning workspace for next example
rm(climate, climate.autosum, climate.distances, climate.psi)
```


# Variable contribution to dissimilarity

*What variables are more important in explaining the dissimilarity between two sequences?*, or in other words, *what variables contribute the most to the dissimilarity between two sequences?* One reasonable answer is: the one that reduces dissimilarity the most when removed from the data. 

This section explains how to use the function **workflowImportance** to evaluate the importance of given variables in explaining differences between sequences.

First, we prepare the data. It is again *sequencesMIS*, but with only three groups selected (MIS 4 to 6) to simplify the analysis.

```{r}
#getting example data
data(sequencesMIS)
sequences <- sequencesMIS[sequencesMIS$MIS %in% c("MIS-4", "MIS-5", "MIS-6"),]

#preparing sequences
sequences <- prepareSequences(
  sequences = sequences,
  grouping.column = "MIS",
  time.column = NULL,
  merge.mode = "complete",
  exclude.columns = NULL
)
```

The workflow function is pretty similar to the ones explained above. It allows to work with paired samples (aligned time-series) or with unaligned ones by switching between **workflowPsi** and **workflowPsiPairedSamples** as requested by the user through the argument *paired.samples*. Unlike the other functions in the package, that parallelize the execution of combinations of sequences, this one parallelizes the computation of *psi* on combinations of columns, removing one column each time.

```{r}
psi.importance <- workflowImportance(
  sequences = sequences,
  grouping.column = "MIS",
  time.column = NULL,
  exclude.columns = NULL,
  method = "manhattan",
  diagonal = FALSE,
  parallel.execution = TRUE,
  paired.samples = FALSE
  )
```

The output is a list with two slots named *psi* and *psi.drop*.

The dataframe **psi** contains psi values for each combination of variables (named in the coluns *A* and *B*) computed for all columns in the column *All variables*, and one column per variable named *Without variable_name* containing the psi value when that variable is removed from the compared sequences.

```{r}
kable(psi.importance$psi)
```

This table can be plotted as a bar plot as follows: 

```{r, fig.width = 7, fig.height = 4, eval=TRUE, fig.cap = "Variable importance analysis of three combinations of sequences. The plot suggest that MIS-4 and MIS-6 are more similar (both are glacial periods), and that the column Quercus is the one with a higher contribution to dissimilarity between sequences."}
#extracting object
psi.df <- psi.importance$psi

#to long format
psi.df.long <- tidyr::gather(psi.df, variable, psi, 3:ncol(psi.df))

#creating column with names of the sequences
psi.df.long$name <- paste(psi.df.long$A, psi.df.long$B, sep=" - ")

#plot
ggplot(data=psi.df.long, aes(x=variable, y=psi, fill=psi)) + 
  geom_bar(stat = "identity") + 
  coord_flip() + 
  facet_wrap("name") +
  scale_fill_viridis() +
  ggtitle("Contribution of separated variables to dissimilarity.") +
  labs(fill = "Psi")
```

The second table, named **psi.drop** contains the drop in psi values, in percentage, when the given variable is removed from the analysis. Large positive numbers indicate that dissimilarity drops (increase in similarity) when the given variable is removed, confirming that the variable is important to explain the dissimilarity between both sequences. Negative values indicate an increase in dissimilarity between the sequences when the variable is dropped.

In summary:


+  High psi-drop value: variable contributes to dissimilarity.
+  Low or negative psi-drop value: variable contributes to similarity.

```{r}
kable(psi.importance$psi.drop)
```

```{r, fig.width = 7, fig.height = 4, eval=TRUE, fig.cap = "Drop in psi values, represented as percentage, when a variable is removed from the analysis. Negative values indicate a contribution to similarity, while positive values indicate a contribution to dissimilarity. The plot suggest that Quercus is the variable with a higher contribution to dissimilarity, while Pinus has the higher contribution to similarity."}
#extracting object
psi.drop.df <- psi.importance$psi.drop

#to long format
psi.drop.df.long <- tidyr::gather(psi.drop.df, variable, psi, 3:ncol(psi.drop.df))

#creating column with names of the sequences
psi.drop.df.long$name <- paste(psi.drop.df.long$A, psi.drop.df.long$B, sep=" - ")

#plot
ggplot(data=psi.drop.df.long, aes(x=variable, y=psi, fill=psi)) + 
  geom_bar(stat = "identity") + 
  coord_flip() + 
  facet_wrap("name") +
  scale_fill_viridis(direction = -1) +
  ggtitle("Drop in dissimilarity when variables are removed.") +
  ylab("Drop in dissimilarity (%)") +
  labs(fill = "Psi drop (%)")
```

```{r}
#cleaning environment for next example
rm(psi.df, psi.df.long, psi.drop.df, psi.drop.df.long, psi.importance, sequences, sequencesMIS)
```


# Finding the section in a long sequence more similar to a given short sequence (irregular time-series)

In this scenario the user has one short and one long sequence, and the goal is to find the section in the long sequence that better matches the short one. To recreate this scenario we will use the dataset *sequencesMIS*. We will extract the first 10 samples as short sequence, and the first 40 samples as long sequence. These small subsets are selected to speed-up the execution time of this example. 

A more realistic example would be to select, for example, the group "MIS-5" as short sequence, and the complete sequence as long sequence, in order to find what segments in *sequencesMIS* is more similar to the "MIS-5" group.

```{r}
#loading the data
data(sequencesMIS)

#removing grouping column
sequencesMIS$MIS <- NULL

#subsetting to get the short sequence
MIS.short <- sequencesMIS[1:10, ]

#subsetting to get the long sequence
MIS.long <- sequencesMIS[1:40, ]
```

The sequences have to be prepared and transformed. For simplicity, the sequences are named *short* and *long*, and the grouping column is named *id*, but the user can name them at will. Since the data represents community composition, a Hellinger transformation is applied.


```{r}
MIS.short.long <- prepareSequences(
  sequence.A = MIS.short,
  sequence.A.name = "short",
  sequence.B = MIS.long,
  sequence.B.name = "long",
  grouping.column = "id",
  transformation = "hellinger"
)
kable(MIS.short.long)
```

The function **worflowShortInLong** shown below is going to subset the long sequence in sizes between *min.length* and *max.length*. In the example below this search space is reduced to the minimum (the rows of *MIS.short* plus and minus one) to speed-up the execution of this example. If left empty, the length of the segment in the long sequence to be matched will have the same number of samples as the short sequence. In the example below we look for segments of the same length, two samples shorter, and two samples longer than the shorter sequence.

```{r}
MIS.psi <- worflowShortInLong(
  sequences = MIS.short.long,
  grouping.column = "id",
  method = "manhattan",
  paired.samples = FALSE,
  min.length = nrow(MIS.short) - 2,
  max.length = nrow(MIS.short) + 2
)
```


The function returns a dataframe with three columns: *first.row* (first row of the matched segment of the long sequence), *last.row* (last row of the matched segment of the long sequence), and *psi* (ordered from lower to higher). In this case, since the long sequence contains the short sequence, the first row shows a perfect match.

```{r}
kable(MIS.psi[1:10, ])
```

Subsetting the long sequence to obtain the segment best matching with the short sequence goes as follows.

```{r}
#indices of the best matching segment
best.match.indices <- MIS.psi[1, "first.row"]:MIS.psi[1, "last.row"]

#subsetting by these indices
best.match <- MIS.long[best.match.indices, ]

#testing that the values in the best matching segment and the short sequence are identical
best.match == MIS.short
```

```{r}
#cleaning workspace
rm(best.match, MIS.long, MIS.psi, MIS.short, MIS.short.long, sequencesMIS, best.match.indices)
```


# Finding the section in a long sequence more similar to a given short sequence (regular time-series, paired samples)

When regular time-series are provided, and the analysis needs to be done comparing only aligned samples, the argument *paired.samples* can be set to TRUE, and instead of the least-cost algorithm to find the minimized distance between sequences, the function **distancePairedSamples** (shown above) is used to compute the distance between sequences of the same length (short sequence versus subsets of the long sequence). In such a case, the arguments *min.length* and *max.length* are irrelevant, and the sample-size of the matching segments in the long sequence have equals the sample-size of the short sequence. This application is ideal when the user has regular time-series. 

The example below shows how it is done with the *climateShort* and *climateLong* datasets. The goal is to find the subset in *climateLong* better matching *climateShort*, with the same number of rows (11) as *climateShort*.

```{r}
#loading sample data
data(climateLong) #has "age" column
data(climateShort) #no "age" column

#merging and scaling both datasets
climate.short.long <- prepareSequences(
  sequence.A = climateShort,
  sequence.A.name = "short",
  sequence.B = climateLong,
  sequence.B.name = "long",
  time.column = "age",
  grouping.column = "id",
  transformation = "scale"
)

#computing psi
climate.psi <- worflowShortInLong(
  sequences = climate.short.long,
  grouping.column = "id",
  time.column = "age",
  method = "manhattan",
  paired.samples = TRUE
)
kable(climate.psi[1:10, ])
```

Since *climateShort* is a subset of *climateLong*, there is a perfect match from the rows 17 to 27.

In this case the solutions are computed among sequences of the same length, and with distances computed only between aligned samples. 

```{r}
#cleaning workspace
rm(climateLong, climateShort, climate.short.long, climate.psi)
```


# Sequence slotting: combining samples of two sequences into a single composite sequence

**THIS SECTION IS A WORK IN PROGRESS**

Under this scenario, the objective is to combine two sequences in order to obtain a single composite sequence containing the samples in both sequences ordered in a way that minimizes the multivariate distance between consecutive samples.

Within this scenario, there are two possibilities: 1) None of the sequences has a *time.column* containing time/age/depth values; 2) One of the sequences has a *time.column*. 

## None of the sequences has time/age/depth columns.

In this case, the target is to obtain a single ordered sequence containing the samples of both sequences (a.k.a, a composite sequence).

To develop this study case I will use the **pollenGP** dataset, which contains 200 samples, with 40 pollen types each, and will separate the first 20 samples into two different datasets with 10 randomly selected samples each. We assume that these sequences do not have depth or age, but these columns will be kept so the result can be assessed. That is why these columns are added to the *exclude.columns* argument.

```{r}
#loading the data
data(pollenGP)

#getting first 20 samples
pollenGP <- pollenGP[1:20, ]

#sampling indices
set.seed(10) #to get same result every time
sampling.indices <- sort(sample(1:20, 10))

#subsetting the sequence
A <- pollenGP[sampling.indices, ]
B <- pollenGP[-sampling.indices, ]

#preparing the sequences
AB <- prepareSequences(
  sequence.A = A,
  sequence.A.name = "A",
  sequence.B = B,
  sequence.B.name = "B",
  exclude.columns = c("depth", "age"),
  transformation = "hellinger"
)
kable(AB)
```

First, we need to obtain the least-cost path from the distance matrix.

```{r, , fig.width = 7, fig.height = 4, eval=TRUE, fig.cap = "Least cost matrix and path between sequences A and B."}
#distance matrix
AB.distance.matrix <- distanceMatrix(
  sequences = AB,
  exclude.columns = c("depth", "age"),
)

#least cost matrix
AB.least.cost.matrix <- leastCostMatrix(
  distance.matrix = AB.distance.matrix,
  diagonal = FALSE
)

#least cost path
AB.least.cost.path <- leastCostPath(
  distance.matrix = AB.distance.matrix,
  least.cost.matrix = AB.least.cost.matrix,
  diagonal = FALSE
)

kable(AB.least.cost.path)

#visualizing output
plotMatrix(
  distance.matrix = AB.distance.matrix,
  least.cost.path = AB.least.cost.path,
  color.palette = "viridis"
)
```

**Next: generating composite sequence from the least-cost path dataframe**

```{r}
#input parameters
i<-1
least.cost.path <- AB.least.cost.path
sequence.names = unlist(strsplit(names(least.cost.path)[i], split='|', fixed=TRUE))

```


## One of the sequences has a time/age/depth column.


# Attribute transfer

