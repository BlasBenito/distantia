% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/distantia.R
\name{distantia}
\alias{distantia}
\title{Time Series Dissimilarity Analysis}
\usage{
distantia(
  tsl = NULL,
  distance = "euclidean",
  diagonal = TRUE,
  weighted = TRUE,
  ignore_blocks = FALSE,
  lock_step = FALSE,
  repetitions = 0L,
  permutation = "restricted_by_row",
  block_size = NULL,
  seed = 1
)
}
\arguments{
\item{tsl}{(required, time series list) list of zoo time series. Default: NULL}

\item{distance}{(optional, character vector) name or abbreviation of the distance method. Valid values are in the columns "names" and "abbreviation" of the dataset \link{distances}. Default: "euclidean".}

\item{diagonal}{(optional, logical vector). If TRUE, diagonals are included in the dynamic time warping computation. Default: TRUE}

\item{weighted}{(optional, logical vector) If TRUE, diagonal is set to TRUE, and diagonal cost is weighted by a factor of 1.414214. Default: TRUE}

\item{ignore_blocks}{(optional, logical vector). If TRUE, blocks of consecutive least cost path coordinates are trimmed to avoid inflating the psi dissimilarity Irrelevant if \code{diagonal = TRUE}. Default: FALSE.}

\item{lock_step}{(optional, logical vector) If TRUE, time-series captured at the same times are compared sample wise (with no dynamic time warping). Requires time series in argument \code{tsl} to be fully aligned, or it will return an error. Default: FALSE.}

\item{repetitions}{(optional, integer vector) number of permutations to compute the p-value. If 0, p-values are not computed. Otherwise, the minimum is 2. The resolution of the p-values and the overall computation time depends on the number of permutations. Default: 0}

\item{permutation}{(optional, character vector) permutation method, only relevant when \code{repetitions} is higher than zero. Valid values are: "restricted_by_row", "restricted", "free_by_row", and "free". Default: "restricted_by_row".}

\item{block_size}{(optional, integer) Size of the row blocks for the restricted permutation test. Only relevant when permutation methods are "restricted" or "restricted_by_row" and \code{repetitions} is higher than zero. A block of size \code{n} indicates that a row can only be permuted within a block of \code{n} adjacent rows. If NULL, defaults to the rounded one tenth of the shortest time series in \code{tsl}. Default: NULL.}

\item{seed}{(optional, integer) initial random seed to use for replicability when computing p-values. Default: 1}
}
\value{
Data frame with the attribute \code{type} set to \code{distantia_df} and the following columns:
\itemize{
\item \code{x}: time series name.
\item \code{y}: time series name.
\item \code{distance}: name of the distance metric.
\item \code{diagonal}: value of the argument \code{diagonal}.
\item \code{weighted}: value of the argument \code{weighted}.
\item \code{ignore_blocks}: value of the argument \code{ignore_blocks}.
\item \code{lock_step}: value of the argument \code{lock_step}.
\item \code{repetitions} (only if \code{repetitions > 0}): value of the argument \code{repetitions}.
\item \code{permutation} (only if \code{repetitions > 0}): name of the permutation method used to compute p-values.
\item \code{seed} (only if \code{repetitions > 0}): random seed used to in the permutations.
\item \code{psi}: psi dissimilarity of the sequences \code{x} and \code{y}.
\item \code{null_mean} (only if \code{repetitions > 0}): mean of the null distribution of psi values computed from the permutaitons.
\item \code{null_sd} (only if \code{repetitions > 0}): standard deviation of the null distribution of psi values.
\item \code{p_value}  (only if \code{repetitions > 0}): proportion of scores smaller or equal than \code{psi} in the null distribution.
}
}
\description{
This function combines \emph{dynamic time warping} or \emph{lock-step comparison} with the \emph{psi dissimilarity score} and \emph{permutation methods} to assess dissimilarity between pairs time series or any other sort of data composed of events ordered across a relevant dimension.

\strong{Dynamic Time Warping} (DTW) is an algorithm that finds the optimal alignment between two time series by minimizing the cumulative distance between them. It identifies the least-cost path through a distance matrix, which maps all points of one time series to another. The resulting sum of distances along this path serves as a measure of time-series similarity. DTW disregards the exact timing of samples and focuses on their order, making it suitable for comparing both \emph{regular and irregular time series of the same or different lengths}, such as phenological data from different latitudes or elevations, time series from various years or periods, and movement trajectories like migration paths.

On the other hand, the \strong{lock-step} method sums pairwise distances between samples in \emph{regular or irregular time series of the same length}, preferably captured at the same times. This method is an alternative to dynamic time warping when the goal is to assess the synchronicity of two time series.

The \strong{psi score} normalizes the cumulative sum of distances between two time series by the cumulative sum of distances between their consecutive samples to generate a comparable dissimilarity score. If for two time series \eqn{x} and \eqn{y} \eqn{D_xy} represents the cumulative sum of distances between them, either resulting from dynamic time warping or the lock-step method, and \eqn{S_xy} represents the cumulative sum of distances of their consecutive samples, then the psi score can be computed in two ways depending on the scenario:

\strong{Equation 1:} \eqn{\psi = \frac{D_{xy} - S_{xy}}{S_{xy}}}

\strong{Equation 2:} \eqn{\psi = \frac{D_{xy} - S_{xy}}{S_{xy}} + 1}

When $D_xy$ is computed via dynamic time warping \strong{ignoring the distance matrix diagonals} (\code{diagonal = FALSE}), then \emph{Equation 1} is used. On the other hand, if $D_xy$ results from the lock-step method (\code{lock_step = TRUE}), or from dynamic time warping considering diagonals (\code{diagonal = TRUE}), then \emph{Equation 2} is used instead:

In both equations, a psi score of zero indicates maximum similarity.

\strong{Permutation methods} are provided here to help assess the robustness of observed psi scores by direct comparison with a null distribution of psi scores resulting from randomized versions of the compared time series. The fraction of null scores smaller than the observed score is returned as a \emph{p_value} in the function output and interpreted as "the probability of finding a higher similarity (lower psi score) by chance".

In essence, restricted permutation is useful to answer the question "how robust is the similarity between two time series?"

Four different permutation methods are available:
\itemize{
\item \strong{"restricted"}: Separates the data into blocks of contiguous rows, and re-shuffles data points randomly within these blocks, independently by row and column. Applied when the data is structured in blocks that should be preserved during permutations (e.g., "seasons", "years", "decades", etc) and the columns represent independent variables.
\item \strong{"restricted_by_row"}: Separates the data into blocks of contiguous rows, and re-shuffles complete rows within these blocks. This method is suitable for cases where the data is organized into blocks as described above, but columns represent interdependent data (e.g., rows represent percentages or proportions), and maintaining the relationships between data within each row is important.
\item \strong{"free"}: Randomly re-shuffles data points across the entire time series, independently by row and column. This method is useful for loosely structured time series where data independence is assumed. When the data exhibits a strong temporal structure, this approach may lead to an overestimation of the robustness of dissimilarity scores.
\item \strong{"free_by_row"}: Randomly re-shuffles complete rows across the entire time series. This method is useful for loosely structured time series where dependency between columns is assumed (e.g., rows represent percentages or proportions). This method has the same drawbacks as the "free" method, when the data exhibits a strong temporal structure.
}

This function allows computing dissimilarity between pairs of time series using different combinations of arguments at once. For example, when the argument \code{distance} is set to \code{c("euclidean", "manhattan")}, the output data frame will show two dissimilarity scores for each pair of time series, one based on euclidean distances, and another based on manhattan distances. The same happens for most other parameters.

This function supports progress bars generated by the \code{progressr} package. See examples.

This function also accepts a parallelization setup via \code{\link[future:plan]{future::plan()}}, but it might only be worth it for large time series lists.
}
\examples{
#parallelization setup (not worth it for this data size)
future::plan(
  future::multisession,
  workers = 2 #set to parallelly::availableWorkers() - 1
)

#progress bar
if(interactive()){
  progressr::handlers(global = TRUE)
}

#three time series
#climate and ndvi in Fagus sylvatica stands
#in Spain, Germany, and Sweden
#scaled and centered
tsl <- tsl_initialize(
  x = fagus_dynamics,
  id_column = "site",
  time_column = "date"
) |>
  tsl_transform(
    f = f_scale
  )

if(interactive()){
  tsl_plot(
    tsl = tsl,
    guide_columns = 3
    )
}

#dynamic time warping dissimilarity analysis
#-------------------------------------------
#permutation restricted by row because
#ndvi depends on temperature and rainfall
#block size is 6 because data is monthly
#to keep permutation restricted to 6 months periods
df_dtw <- distantia(
  tsl = tsl,
  distance = "euclidean",
  repetitions = 10, #increase to 100 or more
  permutation = "restricted_by_row",
  block_size = 6,
  seed = 1
)

#focus on the important details
df_dtw[, c("x", "y", "psi", "p_value")]
#smaller psi values indicate higher similarity
#p-values indicate chance of
#finding a psi smaller than the observed

#visualize dynamic time warping
if(interactive()){

  distantia_plot(
    tsl = tsl_subset(
      tsl = tsl,
      names = c("Spain", "Sweden")
    ),
    distance = "euclidean",
    matrix_type = "cost"
  )

}

#recreating the null distribution
#direct call to C++ function
#use same args as in distantia() call
psi_null <- null_psi_cpp(
  x = tsl[["Spain"]],
  y = tsl[["Sweden"]],
  repetitions = 10, #increase to 100 or more
  distance = "euclidean",
  permutation = "restricted_by_row",
  block_size = 6,
  seed = 1
)

#compare null mean with output of distantia()
mean(psi_null)
df_dtw$null_mean[3]


#lock-step dissimilarity analysis
#---------------------------------
df_lock_step <- distantia(
  tsl = tsl,
  distance = "euclidean",
  repetitions = 10, #increase to 100 or more
  permutation = "restricted_by_row",
  block_size = 6,
  lock_step = TRUE
)

#focus on the important details
df_lock_step[, c("x", "y", "psi", "p_value")]

#recreating the null distribution
psi_null <- null_psi_lock_step_cpp(
  x = tsl[["Spain"]],
  y = tsl[["Sweden"]],
  repetitions = 10, #increase to 100 or more
  distance = "euclidean",
  permutation = "restricted_by_row",
  block_size = 6,
  seed = 1
)

#compare null mean with output of distantia()
mean(psi_null)
df_lock_step$null_mean[3]


#combinations of parameters
#---------------------------------
#most distantia arguments accept vectors
#the function combines these arguments
df_multiple <- distantia(
  tsl = tsl,
  distance = c("euclidean", "manhattan")
)

df_multiple[, c(
  "x",
  "y",
  "distance",
  "psi"
)]

#see distantia_aggregate to average results
#from different argument combinations
df <- distantia_aggregate(
  df = df_multiple
  )

df[, c("x", "y", "psi")]


#disable parallelization
future::plan(
  future::sequential
)
}
\seealso{
Other dissimilarity_analysis: 
\code{\link{distantia_aggregate}()},
\code{\link{distantia_boxplot}()},
\code{\link{distantia_cluster_hclust}()},
\code{\link{distantia_cluster_kmeans}()},
\code{\link{distantia_importance}()},
\code{\link{distantia_matrix}()},
\code{\link{distantia_plot}()},
\code{\link{distantia_to_sf}()},
\code{\link{utils_block_size}()},
\code{\link{utils_importance_df_to_wide}()}
}
\concept{dissimilarity_analysis}
